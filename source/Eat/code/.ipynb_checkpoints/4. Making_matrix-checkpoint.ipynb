{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from gensim import models\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_punctuation_marks_tag(word):\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\".\",\"\")\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\"!\",\"\")\n",
    "    word = word.replace(\":\",\"\")\n",
    "    word = word.replace(\"?\",\"\")\n",
    "    word = word.replace(\"~\",\"\")\n",
    "    word = word.replace(\"\\\\\",\"\")\n",
    "    word = word.replace(\"\\\"\",\"\")\n",
    "    word = word.replace(\";\",\"\")\n",
    "    return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat_info = pd.read_csv('../data/translated_eat_info.csv')\n",
    "eat_review = pd.read_csv('../data/translated_eat_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69014054dc2242fab1db7f19ec923f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=22150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eat_review_by_user = pd.DataFrame(index = eat_review['u_id'].unique(), columns=['reviews'])\n",
    "\n",
    "for id in tqdm(eat_review['u_id'].unique()):\n",
    "    review_all = ''\n",
    "    for review in eat_review.loc[eat_review['u_id']==id,'review_eng']:\n",
    "        if type(review) != float:\n",
    "            review_all += review+'. '\n",
    "    eat_review_by_user.loc[id,'reviews'] = review_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat_info['tags']=''\n",
    "eat_review_by_user['tags']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>category</th>\n",
       "      <th>main_mn</th>\n",
       "      <th>price</th>\n",
       "      <th>opng_tm</th>\n",
       "      <th>rating</th>\n",
       "      <th>rvw_cnt</th>\n",
       "      <th>tags</th>\n",
       "      <th>p_id</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>놀부만두</td>\n",
       "      <td>서울특별시 동대문구 휘경2동 276-33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>냉모밀</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>{'월-금,일': '오전 11시 - 오후 8시 30분 '}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>721</td>\n",
       "      <td>As a local restaurant, it was moderately shabb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>민벅 건대점</td>\n",
       "      <td>서울특별시 광진구 화양동 10-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>알리오올리오</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>{'매일': '오전 11시 30분 - 오후 10시 (구정 추석 당일 3시 오픈)'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1832</td>\n",
       "      <td>If you order 1 menu per person, give me Gorgon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>뉴델리</td>\n",
       "      <td>서울시 동대문구 회기동 3-182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>치킨 탄두리 (한마리)</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>{'매일': '오전 11시 - 오후 10시 '}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>741</td>\n",
       "      <td>You can enjoy delicious Indian curry at an old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>강릉스낵</td>\n",
       "      <td>서울특별시 양천구 목동 406-65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>직송 모듬 회</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>{'월-금': '오후 5시 - 오전 1시 ', '토/일': '오후 4시 - 오전 1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>218</td>\n",
       "      <td>Tteokbokki is spicy and delicious. Fried chick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>여기가전집</td>\n",
       "      <td>서울특별시 구로구 구로3동 1124-34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>모둠전</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>{'월-금': '오후 2시 - 오전 2시 '}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3276</td>\n",
       "      <td>The pancakes are delicious~ Potato pancake, pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                 address category       main_mn    price  \\\n",
       "0    놀부만두  서울특별시 동대문구 휘경2동 276-33      NaN           냉모밀   6000.0   \n",
       "1  민벅 건대점      서울특별시 광진구 화양동 10-1      NaN        알리오올리오   9900.0   \n",
       "2     뉴델리      서울시 동대문구 회기동 3-182      NaN  치킨 탄두리 (한마리)  15000.0   \n",
       "3    강릉스낵     서울특별시 양천구 목동 406-65      NaN       직송 모듬 회  60000.0   \n",
       "4   여기가전집  서울특별시 구로구 구로3동 1124-34      NaN           모둠전  18000.0   \n",
       "\n",
       "                                             opng_tm  rating  rvw_cnt tags  \\\n",
       "0                   {'월-금,일': '오전 11시 - 오후 8시 30분 '}     NaN      NaN        \n",
       "1     {'매일': '오전 11시 30분 - 오후 10시 (구정 추석 당일 3시 오픈)'}     NaN      NaN        \n",
       "2                         {'매일': '오전 11시 - 오후 10시 '}     NaN      NaN        \n",
       "3  {'월-금': '오후 5시 - 오전 1시 ', '토/일': '오후 4시 - 오전 1...     NaN      NaN        \n",
       "4                          {'월-금': '오후 2시 - 오전 2시 '}     NaN      NaN        \n",
       "\n",
       "   p_id                                            reviews  \n",
       "0   721  As a local restaurant, it was moderately shabb...  \n",
       "1  1832  If you order 1 menu per person, give me Gorgon...  \n",
       "2   741  You can enjoy delicious Indian curry at an old...  \n",
       "3   218  Tteokbokki is spicy and delicious. Fried chick...  \n",
       "4  3276  The pancakes are delicious~ Potato pancake, pe...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eat_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5351</th>\n",
       "      <td>As a local restaurant, it was moderately shabb...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>I went to Pyongyang naengmyeon in Jegi-dong an...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>Among the three, kimchi dumplings were the bes...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13580</th>\n",
       "      <td>The combination of kimchi dumplings and cold b...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews tags\n",
       "5351   As a local restaurant, it was moderately shabb...     \n",
       "3024   I went to Pyongyang naengmyeon in Jegi-dong an...     \n",
       "5941   Among the three, kimchi dumplings were the bes...     \n",
       "13580  The combination of kimchi dumplings and cold b...     \n",
       "6953                                                         "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eat_review_by_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/stop_words.txt','r',-1,'utf-8') as f:\n",
    "    stop_words = set(f.read().split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '*',\n",
       " '+',\n",
       " '+0',\n",
       " '+_+',\n",
       " '0th',\n",
       " '1',\n",
       " '1st',\n",
       " '2',\n",
       " '2nd',\n",
       " '3',\n",
       " '3rd',\n",
       " '4',\n",
       " '4b',\n",
       " '4th',\n",
       " '5th',\n",
       " '6',\n",
       " '6th',\n",
       " '7th',\n",
       " '8th',\n",
       " '9',\n",
       " '=',\n",
       " '>',\n",
       " '@',\n",
       " '__',\n",
       " '___________________________________',\n",
       " 'a',\n",
       " 'a4',\n",
       " 'about',\n",
       " 'above',\n",
       " 'accumulated',\n",
       " 'acrostic',\n",
       " 'ade',\n",
       " 'admirable',\n",
       " 'adzuki',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'ain',\n",
       " 'ajumma',\n",
       " 'aka',\n",
       " 'al',\n",
       " 'albert',\n",
       " 'all',\n",
       " 'alla',\n",
       " 'alle',\n",
       " 'alli',\n",
       " 'allthe',\n",
       " 'alma',\n",
       " 'alongthe',\n",
       " 'altro',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'ame',\n",
       " 'americano',\n",
       " 'amo',\n",
       " 'an',\n",
       " 'anam',\n",
       " 'ancestral',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'anniversary',\n",
       " 'annual',\n",
       " 'ant',\n",
       " 'anticipated',\n",
       " 'any',\n",
       " 'apo',\n",
       " 'arabian',\n",
       " 'archa',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'argent',\n",
       " 'arti',\n",
       " 'as',\n",
       " 'asu',\n",
       " 'at',\n",
       " 'attempted',\n",
       " 'austrian',\n",
       " 'avai',\n",
       " 'average',\n",
       " 'avo',\n",
       " 'awesome',\n",
       " 'b',\n",
       " 'baby',\n",
       " 'badam',\n",
       " 'badi',\n",
       " 'bahn',\n",
       " 'bal',\n",
       " 'baltic',\n",
       " 'bam',\n",
       " 'bb',\n",
       " 'be',\n",
       " 'bean',\n",
       " 'beans',\n",
       " 'because',\n",
       " 'been',\n",
       " 'beep',\n",
       " 'bef',\n",
       " 'before',\n",
       " 'beforethe',\n",
       " 'beginning',\n",
       " 'being',\n",
       " 'belgian',\n",
       " 'below',\n",
       " 'between',\n",
       " 'bible',\n",
       " 'billiard',\n",
       " 'birthday',\n",
       " 'bismarck',\n",
       " 'bok',\n",
       " 'bon',\n",
       " 'both',\n",
       " 'boththe',\n",
       " 'bottom',\n",
       " 'boyfriend',\n",
       " 'breaktime',\n",
       " 'breast',\n",
       " 'brilliant',\n",
       " 'bts',\n",
       " 'buchu',\n",
       " 'buckwheat',\n",
       " 'bul',\n",
       " 'burmese',\n",
       " 'busi',\n",
       " 'but',\n",
       " 'by',\n",
       " 'calabrese',\n",
       " 'californian',\n",
       " 'can',\n",
       " 'canoli',\n",
       " 'carious',\n",
       " 'carnivorous',\n",
       " 'carper',\n",
       " 'central',\n",
       " 'ceo',\n",
       " 'cesar',\n",
       " 'cha',\n",
       " 'chae',\n",
       " 'cham',\n",
       " 'char',\n",
       " 'cheek',\n",
       " 'cheong',\n",
       " 'chi',\n",
       " 'chickpea',\n",
       " 'chicory',\n",
       " 'chilean',\n",
       " 'chinatown',\n",
       " 'chirashi',\n",
       " 'chocolat',\n",
       " 'chok',\n",
       " 'chou',\n",
       " 'choy',\n",
       " 'chu',\n",
       " 'chun',\n",
       " 'chupa',\n",
       " 'cj',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'coastal',\n",
       " 'coco',\n",
       " 'coeducational',\n",
       " 'colombian',\n",
       " 'combi',\n",
       " 'combined',\n",
       " 'combo',\n",
       " 'comme',\n",
       " 'commendable',\n",
       " 'complete',\n",
       " 'consecutive',\n",
       " 'continued',\n",
       " 'costal',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'couple',\n",
       " 'cro',\n",
       " 'crown',\n",
       " 'cu',\n",
       " 'd',\n",
       " 'da',\n",
       " 'dae',\n",
       " 'dak',\n",
       " 'dalia',\n",
       " 'dan',\n",
       " 'darth',\n",
       " 'dary',\n",
       " 'de',\n",
       " 'decade',\n",
       " 'deducted',\n",
       " 'deng',\n",
       " 'di',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'din',\n",
       " 'dina',\n",
       " 'dinosaur',\n",
       " 'divine',\n",
       " 'do',\n",
       " 'doenjang',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'dong',\n",
       " 'dora',\n",
       " 'double',\n",
       " 'doubled',\n",
       " 'down',\n",
       " 'draft',\n",
       " 'driving',\n",
       " 'due',\n",
       " 'dul',\n",
       " 'dum',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'earlier',\n",
       " 'early',\n",
       " 'east',\n",
       " 'eastern',\n",
       " 'edible',\n",
       " 'eg',\n",
       " 'egyptian',\n",
       " 'eight',\n",
       " 'eighth',\n",
       " 'eighty',\n",
       " 'el',\n",
       " 'eleven',\n",
       " 'embankment',\n",
       " 'emi',\n",
       " 'emmental',\n",
       " 'emoji',\n",
       " 'end',\n",
       " 'ending',\n",
       " 'ends',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'entering',\n",
       " 'entire',\n",
       " 'equivalent',\n",
       " 'eran',\n",
       " 'error',\n",
       " 'etc',\n",
       " 'ethiopian',\n",
       " 'eul',\n",
       " 'eurasian',\n",
       " 'evian',\n",
       " 'excelent',\n",
       " 'excellent',\n",
       " 'exceptional',\n",
       " 'exciting',\n",
       " 'exemplary',\n",
       " 'expected',\n",
       " 'expects',\n",
       " 'experienced',\n",
       " 'extended',\n",
       " 'extramarital',\n",
       " 'extraordinary',\n",
       " 'failed',\n",
       " 'failing',\n",
       " 'fairy',\n",
       " 'famous',\n",
       " 'fantastic',\n",
       " 'fav',\n",
       " 'favorite',\n",
       " 'feng',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifteenth',\n",
       " 'fifth',\n",
       " 'fifty',\n",
       " 'filial',\n",
       " 'final',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'finishing',\n",
       " 'finnish',\n",
       " 'first',\n",
       " 'five',\n",
       " 'flat',\n",
       " 'flawless',\n",
       " 'flesh',\n",
       " 'fm',\n",
       " 'following',\n",
       " 'for',\n",
       " 'forced',\n",
       " 'formaggi',\n",
       " 'forthe',\n",
       " 'forty',\n",
       " 'foul',\n",
       " 'four',\n",
       " 'fourth',\n",
       " 'franchise',\n",
       " 'frau',\n",
       " 'from',\n",
       " 'ft',\n",
       " 'fucking',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'further',\n",
       " 'galat',\n",
       " 'gallic',\n",
       " 'gam',\n",
       " 'ganja',\n",
       " 'gat',\n",
       " 'genius',\n",
       " 'gente',\n",
       " 'ginseng',\n",
       " 'girlfriend',\n",
       " 'gis',\n",
       " 'gmo',\n",
       " 'gon',\n",
       " 'gong',\n",
       " 'good',\n",
       " 'goodby',\n",
       " 'gram',\n",
       " 'grana',\n",
       " 'grandma',\n",
       " 'granny',\n",
       " 'great',\n",
       " 'gross',\n",
       " 'guan',\n",
       " 'guaranteed',\n",
       " 'h',\n",
       " 'h2',\n",
       " 'ha',\n",
       " 'had',\n",
       " 'hadi',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hagwon',\n",
       " 'hahm',\n",
       " 'half',\n",
       " 'hamburg',\n",
       " 'han',\n",
       " 'hanji',\n",
       " 'hanok',\n",
       " 'hanwoo',\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'hawaiian',\n",
       " 'he',\n",
       " 'heartwarming',\n",
       " 'hehehe',\n",
       " 'hehehehe',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereto',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himalayan',\n",
       " 'himself',\n",
       " 'hinoki',\n",
       " 'his',\n",
       " 'ho',\n",
       " 'hoe',\n",
       " 'holy',\n",
       " 'hoo',\n",
       " 'hooray',\n",
       " 'hoti',\n",
       " 'how',\n",
       " 'however',\n",
       " 'https',\n",
       " 'hua',\n",
       " 'hundred',\n",
       " 'hungarian',\n",
       " 'i',\n",
       " 'id',\n",
       " 'if',\n",
       " 'ifc',\n",
       " 'impeccable',\n",
       " 'importanti',\n",
       " 'impressive',\n",
       " 'in',\n",
       " 'ina',\n",
       " 'incomparable',\n",
       " 'incredible',\n",
       " 'indescribable',\n",
       " 'indic',\n",
       " 'indonesian',\n",
       " 'ini',\n",
       " 'init',\n",
       " 'initial',\n",
       " 'interesting',\n",
       " 'inthe',\n",
       " 'into',\n",
       " 'ipa',\n",
       " 'irreplaceable',\n",
       " 'irresistible',\n",
       " 'is',\n",
       " 'isit',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'ita',\n",
       " 'itas',\n",
       " 'itd',\n",
       " 'ited',\n",
       " 'ithe',\n",
       " 'iti',\n",
       " 'itin',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'j',\n",
       " 'jamaican',\n",
       " 'jang',\n",
       " 'jeon',\n",
       " 'jeong',\n",
       " 'ji',\n",
       " 'jin',\n",
       " 'jjigae',\n",
       " 'jmt',\n",
       " 'jo',\n",
       " 'js',\n",
       " 'jumbo',\n",
       " 'just',\n",
       " 'kai',\n",
       " 'kami',\n",
       " 'kao',\n",
       " 'kaya',\n",
       " 'khao',\n",
       " 'ki',\n",
       " 'kim',\n",
       " 'kimbap',\n",
       " 'kis',\n",
       " 'kiss',\n",
       " 'kochi',\n",
       " 'kona',\n",
       " 'kong',\n",
       " 'ku',\n",
       " 'kua',\n",
       " 'kumo',\n",
       " 'kun',\n",
       " 'kung',\n",
       " 'kya',\n",
       " 'l',\n",
       " 'la',\n",
       " 'lady',\n",
       " 'lang',\n",
       " 'laos',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latin',\n",
       " 'leading',\n",
       " 'least',\n",
       " 'legendary',\n",
       " 'lentil',\n",
       " 'level',\n",
       " 'lfe',\n",
       " 'liked',\n",
       " 'lin',\n",
       " 'll',\n",
       " 'located',\n",
       " 'lola',\n",
       " 'longa',\n",
       " 'lorraine',\n",
       " 'losing',\n",
       " 'loss',\n",
       " 'lost',\n",
       " 'lotus',\n",
       " 'love',\n",
       " 'lp',\n",
       " 'lt',\n",
       " 'm',\n",
       " 'ma',\n",
       " \"ma'am\",\n",
       " 'magic',\n",
       " 'magical',\n",
       " 'mal',\n",
       " 'mala',\n",
       " 'maltese',\n",
       " 'managed',\n",
       " 'manchurian',\n",
       " 'manimal',\n",
       " 'mano',\n",
       " 'manu',\n",
       " 'mapa',\n",
       " 'mapo',\n",
       " 'mara',\n",
       " 'maras',\n",
       " 'marco',\n",
       " 'marshy',\n",
       " 'maximum',\n",
       " 'me',\n",
       " 'median',\n",
       " 'mediterranean',\n",
       " 'mei',\n",
       " 'memorable',\n",
       " 'meno',\n",
       " 'metropolitan',\n",
       " 'mi',\n",
       " 'mid',\n",
       " 'middle',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mille',\n",
       " 'mimi',\n",
       " 'ming',\n",
       " 'minimum',\n",
       " 'minus',\n",
       " 'missed',\n",
       " 'missing',\n",
       " 'mixi',\n",
       " 'mona',\n",
       " 'mongolian',\n",
       " 'monkey',\n",
       " 'monte',\n",
       " 'monthly',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mountainous',\n",
       " 'mouth',\n",
       " 'msg',\n",
       " 'muk',\n",
       " 'mul',\n",
       " 'mung',\n",
       " 'mushroom',\n",
       " 'mushrooms',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'mys',\n",
       " 'myself',\n",
       " 'mysterious',\n",
       " 'n',\n",
       " 'na',\n",
       " 'nabi',\n",
       " 'naked',\n",
       " 'name',\n",
       " 'nameless',\n",
       " 'nami',\n",
       " 'namo',\n",
       " 'nan',\n",
       " 'nashi',\n",
       " 'near',\n",
       " 'neat',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'neer',\n",
       " 'neighboring',\n",
       " 'nem',\n",
       " 'nepal',\n",
       " 'neta',\n",
       " 'next',\n",
       " 'ni',\n",
       " 'nice',\n",
       " 'nicky',\n",
       " 'nightingale',\n",
       " 'nine',\n",
       " 'ninth',\n",
       " 'nish',\n",
       " 'no',\n",
       " 'no2',\n",
       " 'noa',\n",
       " 'nomi',\n",
       " 'nong',\n",
       " 'nor',\n",
       " 'north',\n",
       " 'northeastern',\n",
       " 'northern',\n",
       " 'northwestern',\n",
       " 'nos',\n",
       " 'not',\n",
       " 'notched',\n",
       " 'noti',\n",
       " 'now',\n",
       " 'nox',\n",
       " 'nth',\n",
       " 'num',\n",
       " 'o',\n",
       " 'ocho',\n",
       " 'odo',\n",
       " 'of',\n",
       " 'off',\n",
       " 'offre',\n",
       " 'ok',\n",
       " 'olio',\n",
       " 'ome',\n",
       " 'omi',\n",
       " 'omo',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'oni',\n",
       " 'only',\n",
       " 'oo',\n",
       " 'oolong',\n",
       " 'open',\n",
       " 'opened',\n",
       " 'openi',\n",
       " 'opening',\n",
       " 'or',\n",
       " 'orginal',\n",
       " 'oriental',\n",
       " 'other',\n",
       " 'ou',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outstanding',\n",
       " 'ova',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'overcame',\n",
       " 'overthe',\n",
       " 'own',\n",
       " 'ox',\n",
       " 'ozzy',\n",
       " 'p',\n",
       " 'panna',\n",
       " 'panne',\n",
       " 'pao',\n",
       " 'pea',\n",
       " 'peak',\n",
       " 'pean',\n",
       " 'pen',\n",
       " 'per',\n",
       " 'pera',\n",
       " 'percent',\n",
       " 'perfect',\n",
       " 'perfecta',\n",
       " 'perilla',\n",
       " 'persian',\n",
       " 'peruvian',\n",
       " 'petit',\n",
       " 'pi',\n",
       " 'piggy',\n",
       " 'place',\n",
       " 'plate',\n",
       " 'plated',\n",
       " 'plating',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'pong',\n",
       " 'poop',\n",
       " 'potato',\n",
       " 'pounds',\n",
       " 'ppa',\n",
       " 'pratt',\n",
       " 'prefix',\n",
       " 'preliminary',\n",
       " 'presbyterian',\n",
       " 'previous',\n",
       " 'priceless',\n",
       " 'princess',\n",
       " 'prior',\n",
       " 'pronounced',\n",
       " 'provisional',\n",
       " 'puli',\n",
       " 'putts',\n",
       " 'pyeong',\n",
       " 'qr',\n",
       " 'quatro',\n",
       " 'quattro',\n",
       " 'queen',\n",
       " 'ranked',\n",
       " 'rave',\n",
       " 're',\n",
       " 'receive',\n",
       " 'recorded',\n",
       " 'refreshing',\n",
       " 'regular',\n",
       " 'remaining',\n",
       " 'remote',\n",
       " 'reopened',\n",
       " 'reviewable',\n",
       " 'ripe',\n",
       " 'ripened',\n",
       " 'rised',\n",
       " 'ritual',\n",
       " 'roro',\n",
       " 'ros',\n",
       " 'rose',\n",
       " 'round',\n",
       " 'row',\n",
       " 'royal',\n",
       " 'rucola',\n",
       " 'rural',\n",
       " 'rye',\n",
       " 's',\n",
       " 'sabal',\n",
       " 'sabi',\n",
       " 'sacred',\n",
       " 'sak',\n",
       " 'salary',\n",
       " 'sam',\n",
       " 'same',\n",
       " 'samgyetang',\n",
       " 'san',\n",
       " 'sando',\n",
       " 'sarira',\n",
       " 'scandinavian',\n",
       " 'scheduled',\n",
       " 'sebastian',\n",
       " 'second',\n",
       " 'sensational',\n",
       " 'seoul',\n",
       " 'servant',\n",
       " 'sesame',\n",
       " 'set',\n",
       " 'seven',\n",
       " 'seventeen',\n",
       " 'seventh',\n",
       " 'sfc',\n",
       " 'shabu',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shanghai',\n",
       " 'shao',\n",
       " 'shari',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'shiitake',\n",
       " 'shiro',\n",
       " 'short',\n",
       " 'shortened',\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'shui',\n",
       " 'siam',\n",
       " 'sickle',\n",
       " 'signi',\n",
       " 'silla',\n",
       " 'simi',\n",
       " 'since',\n",
       " 'single',\n",
       " 'sister',\n",
       " 'situated',\n",
       " 'siu',\n",
       " 'six',\n",
       " 'sixth',\n",
       " 'slogan',\n",
       " 'smelled',\n",
       " 'smellin',\n",
       " 'sns',\n",
       " 'so',\n",
       " 'sofa',\n",
       " 'soju',\n",
       " 'some',\n",
       " 'soo',\n",
       " 'sora',\n",
       " 'soul',\n",
       " 'sous',\n",
       " 'south',\n",
       " 'southeast',\n",
       " 'southern',\n",
       " 'southwestern',\n",
       " 'spam',\n",
       " 'spent',\n",
       " 'squash',\n",
       " 'sr',\n",
       " 'ss',\n",
       " 'star',\n",
       " 'starting',\n",
       " 'straight',\n",
       " 'subsequent',\n",
       " 'suburban',\n",
       " 'suburbs',\n",
       " 'successive',\n",
       " 'such',\n",
       " 'sult',\n",
       " 'sumo',\n",
       " 'superlative',\n",
       " 'syllable',\n",
       " 't',\n",
       " 'ta',\n",
       " 'taek',\n",
       " 'taiwanese',\n",
       " 'talian',\n",
       " 'tama',\n",
       " 'tapioca',\n",
       " 'tara',\n",
       " 'tare',\n",
       " 'taro',\n",
       " 'tat',\n",
       " 'ted',\n",
       " 'teddy',\n",
       " 'ten',\n",
       " 'tender',\n",
       " 'teo',\n",
       " 'terra',\n",
       " 'terro',\n",
       " 'text',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'thirty',\n",
       " 'this',\n",
       " 'those',\n",
       " 'thousand',\n",
       " 'three',\n",
       " 'threesome',\n",
       " 'through',\n",
       " 'tic',\n",
       " 'tipi',\n",
       " 'titian',\n",
       " 'to',\n",
       " 'to5',\n",
       " 'toi',\n",
       " 'tomo',\n",
       " 'tomy',\n",
       " 'tongue',\n",
       " 'tonkotsu',\n",
       " 'too',\n",
       " 'top',\n",
       " 'topping',\n",
       " 'tori',\n",
       " 'tory',\n",
       " 'total',\n",
       " 'tous',\n",
       " 'tribute',\n",
       " 'tricolor',\n",
       " 'trident',\n",
       " 'triple',\n",
       " 'tteok',\n",
       " 'turnip',\n",
       " 'tuscan',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'twice',\n",
       " 'twin',\n",
       " 'two',\n",
       " 'u',\n",
       " 'ue',\n",
       " 'uh',\n",
       " 'uing',\n",
       " 'um',\n",
       " 'umeboshi',\n",
       " 'un',\n",
       " 'unbelievable',\n",
       " 'unboiled',\n",
       " 'unchanged',\n",
       " 'uncut',\n",
       " 'under',\n",
       " 'underwent',\n",
       " 'unexpectedly',\n",
       " 'unforgettable',\n",
       " 'uni',\n",
       " 'unique',\n",
       " 'uniqueness',\n",
       " 'unloose',\n",
       " 'unrated',\n",
       " 'unreplaceable',\n",
       " 'unrivaled',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upi',\n",
       " 'upload',\n",
       " 'uploaded',\n",
       " 'uploading',\n",
       " 'uploads',\n",
       " 'upp',\n",
       " 'urban',\n",
       " 'usi',\n",
       " 'uv',\n",
       " 've',\n",
       " 'vegetable',\n",
       " 'vera',\n",
       " 'very',\n",
       " 'vienna',\n",
       " 'viet',\n",
       " 'vietnamese',\n",
       " 'vongole',\n",
       " 'vs',\n",
       " 'wah',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'wasthe',\n",
       " 'wata',\n",
       " 'we',\n",
       " 'weekly',\n",
       " 'wellas',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'west',\n",
       " 'western',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'whopping',\n",
       " 'why',\n",
       " 'will',\n",
       " 'wite',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wonderful',\n",
       " 'wonthe',\n",
       " 'worst',\n",
       " 'worthy',\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'wow',\n",
       " 'x',\n",
       " 'x2',\n",
       " 'xd',\n",
       " 'xiang',\n",
       " 'xiao',\n",
       " 'xx',\n",
       " 'y',\n",
       " 'yagi',\n",
       " 'yam',\n",
       " 'yama',\n",
       " 'yang',\n",
       " 'year',\n",
       " 'years',\n",
       " 'yg',\n",
       " 'yi',\n",
       " 'yo',\n",
       " 'yong',\n",
       " 'yoo',\n",
       " 'yorkshire',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'yoyo',\n",
       " 'yu',\n",
       " 'yuan',\n",
       " 'yuk',\n",
       " 'yul',\n",
       " 'yum',\n",
       " '°',\n",
       " '»',\n",
       " '×',\n",
       " '•',\n",
       " '※',\n",
       " '₩',\n",
       " '■',\n",
       " '□',\n",
       " '▶',\n",
       " '○',\n",
       " '●',\n",
       " '★',\n",
       " '☆',\n",
       " '♡',\n",
       " '♥',\n",
       " '✓',\n",
       " '人',\n",
       " '小',\n",
       " '가',\n",
       " '과',\n",
       " '로',\n",
       " '를',\n",
       " '명',\n",
       " '미국',\n",
       " '시',\n",
       " '에',\n",
       " '와',\n",
       " '은',\n",
       " '을',\n",
       " '의',\n",
       " '이',\n",
       " '하고',\n",
       " '하는',\n",
       " '한',\n",
       " '한국'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_to_txt(text):\n",
    "    if type(text) != str:\n",
    "        return ''\n",
    "    text = word_tokenize(text)\n",
    "    tags_dump = nltk.pos_tag(text)\n",
    "    tags = []\n",
    "    \n",
    "    for word in tags_dump:\n",
    "        if (word[1] == 'JJ') and (word[0] not in stop_words):\n",
    "            tags.append(delete_punctuation_marks_tag(word[0]))\n",
    "            \n",
    "    tags = ','.join(tags)\n",
    "    \n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a1c07e4f39476faa006860abb41517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5462.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(eat_info.index):\n",
    "    eat_info.loc[i,'tags'] = get_tags_to_txt(eat_info.loc[i,'reviews'])\n",
    "    \n",
    "for i in tqdm(eat_review_by_user.index):\n",
    "    eat_review_by_user.loc[i,'tags'] = get_tags_to_txt(eat_review_by_user.loc[i,'reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_tags = set()\n",
    "for tags in eat_info['tags']:\n",
    "    All_tags.update(set(tags.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "for word in All_tags:\n",
    "    try:\n",
    "        f_vec = w2v.get_vector(word)\n",
    "        new_df[word] = f_vec\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "x = new_df.T\n",
    "cluster_count=120\n",
    "model = KMeans(n_clusters=cluster_count)\n",
    "model.fit(x)\n",
    "model.predict(x)\n",
    "Y=x.copy()\n",
    "Y['kmeans_id'] = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "km = list(Y['kmeans_id'])\n",
    "max_count = 0\n",
    "max_count_id = ''\n",
    "for i in range (0, cluster_count):\n",
    "    if km.count(i) > max_count:\n",
    "        max_count = km.count(i);\n",
    "        max_count_id = i;\n",
    "    print(i,': ', km.count(i))\n",
    "max_count_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_df = pd.DataFrame()\n",
    "km_df['group_'+str(max_count_id)] = pd.Series(list(Y[Y['kmeans_id'] == max_count_id].index))\n",
    "for i in range(0, cluster_count):\n",
    "    col_name = 'group_'+str(i)\n",
    "    words = list(Y[Y['kmeans_id'] == i].index)\n",
    "    km_df[col_name] = pd.Series(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "km_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove groups we don't need\n",
    "# rm_groups = [17, 26, 50, 63]\n",
    "# for i in rm_groups:\n",
    "#     group_name = 'group_'+str(i);\n",
    "#     stop_words.update(set(km_df[group_name].dropna()))\n",
    "# with open('../data/stop_words.txt','w',-1,'utf-8') as f:\n",
    "#     f.write('/'.join(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat_info.set_index(eat_info['p_id'],inplace=True,drop=True)\n",
    "del eat_info['p_id']\n",
    "eat_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_matrix = pd.DataFrame(index=eat_info.index,columns=list(km_df.columns))\n",
    "user_matrix = pd.DataFrame(index=eat_review_by_user.index,columns=list(km_df.columns))\n",
    "res_matrix = res_matrix.fillna(0)\n",
    "user_matrix = user_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for id in tqdm(res_matrix.index):\n",
    "    tags = Counter(eat_info.loc[id,'tags'].split(','))\n",
    "    for tag in tags.keys():\n",
    "        for num in range(0,cluster_count):\n",
    "            if tag in set(km_df['group_'+str(num)]):\n",
    "                res_matrix.loc[id,'group_'+str(num)] += tags[tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in tqdm(user_matrix.index):\n",
    "    tags = Counter(eat_review_by_user.loc[id,'tags'].split(','))\n",
    "    for tag in tags.keys():\n",
    "        for num in range(0,cluster_count):\n",
    "            if tag in set(km_df['group_'+str(num)]):\n",
    "                user_matrix.loc[id,'group_'+str(num)] += tags[tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eat_review_score = pd.DataFrame(eat_review, columns=['u_id','p_id','rating'])\n",
    "eat_review_score.sort_values(by=['u_id'], axis=0,inplace=True)\n",
    "eat_review_score.reset_index(drop = True, inplace=True)\n",
    "eat_review_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_matrix.to_csv('../data/res_matrix.csv')\n",
    "user_matrix.to_csv('../data/user_matrix.csv')\n",
    "eat_review_score.to_csv('../data/score_board.csv',index=False)\n",
    "km_df.count().to_csv('../data/group_count.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
